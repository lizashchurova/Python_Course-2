{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импортируем необходимые модули\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "import json\n",
    "import nltk\n",
    "import ssl\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "import collections\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задание №1\n",
    "#Открываем и читаем книгу Ф. М. Достоевского \"Преступление и наказание\"\n",
    "with open(\"dostoevsky.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:28.599383\n"
     ]
    }
   ],
   "source": [
    "#Задание №2\n",
    "#Фиксируем время начала работы анализа текса (%%time не работало, поэтому использовала datetime.datetime.now())\n",
    "time1 = datetime.datetime.now()\n",
    "m = Mystem()\n",
    "#Записываем text в analitics и затем записываем его в формат json\n",
    "analitics = m.analyze(text)\n",
    "with open(\"mystem.json\",\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(analitics, f)\n",
    "#Фиксируем время окончания работы и высчитываем разницу между началом и концом\n",
    "time2 = datetime.datetime.now()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:36.886223\n"
     ]
    }
   ],
   "source": [
    "#Задание №3\n",
    "#Фиксируем время начала работы (%%time не работало, поэтому использовала datetime.datetime.now())\n",
    "time3 = datetime.datetime.now()\n",
    "#Приведем все слова к нижнему регистру, токенизируем, создаем список анализируемых слов\n",
    "words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "morph = MorphAnalyzer()\n",
    "analize_word_list = []\n",
    "for i in words:\n",
    "    analitic_words = morph.parse(i)[0]\n",
    "    analize_word_list.append(analitic_words)\n",
    "\n",
    "#Создаем список лемм, затем находим бля каждого токена часть речи\n",
    "lemmas = []\n",
    "for token in analize_word_list:\n",
    "    first = token[0]\n",
    "    words_dict = (token.word, (token.normal_form, token.tag.POS))\n",
    "    lemmas.append(words_dict)\n",
    "\n",
    "#Сохраняем в файл json\n",
    "with open(\"pymorphy.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(lemmas, f)\n",
    "\n",
    "#Фиксируем время окончания работы и высчитываем разницу между началом и концом\n",
    "time4 = datetime.datetime.now()\n",
    "print(time4-time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN 21.148583624995297\n",
      "CONJ 12.447648693838271\n",
      "ADJF 9.760595259216249\n",
      "None 0.20107202572001528\n",
      "PREP 10.04822502862857\n",
      "ADVB 7.938581635780068\n",
      "VERB 13.446019687854497\n",
      "PRCL 8.108471368741364\n",
      "NPRO 9.482642753073875\n",
      "PRED 0.5306366026354413\n",
      "INFN 2.767697295204916\n",
      "PRTF 0.8419219044854116\n",
      "GRND 1.034391918409918\n",
      "ADJS 0.7790196932307544\n",
      "PRTS 0.3301022026526454\n",
      "COMP 0.4096708117611006\n",
      "INTJ 0.16021246969134906\n",
      "NUMR 0.5645070240802568\n",
      "Топ-20 глаголов: []\n",
      "Топ-20 наречий: []\n"
     ]
    }
   ],
   "source": [
    "#Задание №4\n",
    "POS = []\n",
    "for lemma in lemmas:\n",
    "    POS.append(lemma[1][1])\n",
    "POS = Counter(POS)\n",
    "for key, value in POS.items():\n",
    "    print(key, value / len(lemmas)*100)\n",
    "\n",
    "#Найдем топ-20 распространенных глаголов в тексте\n",
    "verb_list = []\n",
    "for lemma in lemmas:\n",
    "    if lemma == \"VERB\":\n",
    "        verb_list.append(lemma)\n",
    "verb_top = collections.Counter(verb_list).most_common(20)\n",
    "print(\"Топ-20 глаголов:\", verb_top)\n",
    "\n",
    "#Найдем топ-20 распространенных наречий в тексте\n",
    "adverb_list = []\n",
    "for lemma in lemmas:\n",
    "    if lemma == \"ADVB\":\n",
    "        adverb_list.append(lemma)\n",
    "adverb_top = collections.Counter(adverb_list).most_common(20)\n",
    "print(\"Топ-20 наречий:\", adverb_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-25 биграмм:\n",
      "('и', 'не')\n",
      "('как', 'бы')\n",
      "('что', 'он')\n",
      "('да', 'и')\n",
      "('что', 'я')\n",
      "('и', 'в')\n",
      "('может', 'быть')\n",
      "('как', 'будто')\n",
      "('и', 'с')\n",
      "('потому', 'что')\n",
      "('всё', 'это')\n",
      "('и', 'что')\n",
      "('на', 'него')\n",
      "('тотчас', 'же')\n",
      "('так', 'и')\n",
      "('что', 'вы')\n",
      "('я', 'не')\n",
      "('и', 'даже')\n",
      "('катерина', 'ивановна')\n",
      "('и', 'всё')\n",
      "('ничего', 'не')\n",
      "('то', 'есть')\n",
      "('пётр', 'петрович')\n",
      "('то', 'что')\n",
      "('он', 'не')\n",
      "Топ-25 триграмм:\n",
      "('по', 'крайней', 'мере')\n",
      "('до', 'сих', 'пор')\n",
      "('в', 'самом', 'деле')\n",
      "('в', 'то', 'же')\n",
      "('в', 'эту', 'минуту')\n",
      "('то', 'же', 'время')\n",
      "('преступления', 'и', 'наказания')\n",
      "('и', 'как', 'бы')\n",
      "('в', 'том', 'что')\n",
      "('к', 'тому', 'же')\n",
      "('о', 'том', 'что')\n",
      "('на', 'то', 'что')\n",
      "('на', 'этот', 'раз')\n",
      "('он', 'про', 'себя')\n",
      "('и', 'без', 'того')\n",
      "('а', 'между', 'тем')\n",
      "('может', 'быть', 'и')\n",
      "('в', 'последнее', 'время')\n",
      "('не', 'то', 'что')\n",
      "('преступление', 'и', 'наказание')\n",
      "('что', 'может', 'быть')\n",
      "('и', 'тотчас', 'же')\n",
      "('да', 'и', 'не')\n",
      "('на', 'него', 'и')\n",
      "('во', 'всяком', 'случае')\n"
     ]
    }
   ],
   "source": [
    "#Задание №5\n",
    "#Посчитаем топ-25 биграмм и триграмм с помощью nltk.bigrams и nltk.trigrams\n",
    "n_gram_list = []\n",
    "for i in lemmas:\n",
    "    n_gram_list.append(i[0])\n",
    "bigrams = nltk.bigrams(n_gram_list)\n",
    "trigrams = nltk.trigrams(n_gram_list)\n",
    "bigrams_count = collections.Counter(bigrams).most_common(25)\n",
    "trigrams_count = collections.Counter(trigrams).most_common(25)\n",
    "\n",
    "print(\"Топ-25 биграмм:\")\n",
    "for i in bigrams_count:\n",
    "    print(i[0])\n",
    "\n",
    "print(\"Топ-25 триграмм:\")\n",
    "for i in trigrams_count:\n",
    "    print(i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
